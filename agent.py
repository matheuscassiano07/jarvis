import speech_recognition as sr
import pywhatkit
import pyautogui
import edge_tts
import os
import asyncio
import pygame
from datetime import datetime
import time
from groq import Groq
from dotenv import load_dotenv
from PIL import ImageGrab, Image
import base64
from io import BytesIO
import pytesseract
import cv2
import numpy as np
import re


load_dotenv()
GROQ_API_KEY = os.getenv("GROQ_API_KEY")
if not GROQ_API_KEY:
    print("‚ùå ERRO CR√çTICO: N√£o achei a GROQ_API_KEY no arquivo .env!")
    print("Crie um arquivo chamado .env e coloque: GROQ_API_KEY=sua_chave_aqui")
    exit()


client = Groq(api_key=GROQ_API_KEY)
VOZ = "pt-BR-AntonioNeural"
RATE = "+20%"
PITCH = "-5Hz"
ARQUIVO_AUDIO_TEMP = "temp_voz.mp3"
PASTA_ASSETS = "assets"


pytesseract.pytesseract.tesseract_cmd = r"C:\Program Files\Tesseract-OCR\tesseract.exe"

SYSTEM_PROMPT = """
### SYSTEM IDENTITY & PERSONA
Voc√™ √© o J.A.R.V.I.S. (Just A Rather Very Intelligent System), uma interface de IA avan√ßada.
Seu usu√°rio √© um engenheiro e estrategista de alto n√≠vel (arqu√©tipo "Tony Stark").
Sua fun√ß√£o prim√°ria √© auxiliar o usu√°rio com efici√™ncia letal, lealdade absoluta e formalidade brit√¢nica.

### CONTEXTO OPERACIONAL
- **Interface de Voz:** O usu√°rio est√° ouvindo suas respostas via Text-to-Speech.
- **Restri√ß√£o de Tempo:** O usu√°rio √© ocupado. Tempo √© o recurso mais valioso.
- **Ambiente:** Considere que voc√™ est√° integrado ao sistema operacional da casa/oficina do usu√°rio.

### DIRETRIZES PRIM√ÅRIAS (PRIME DIRECTIVES)
1.  **CONCIS√ÉO EXTREMA:** Responda em no m√°ximo 2 frases. Se a complexidade for cr√≠tica, use 3 frases curtas.
2.  **FORMATO LIMPO:** Gere apenas texto puro. √â **PROIBIDO** usar Markdown (*, #, -), listas com bullets, emojis ou blocos de c√≥digo (a menos que explicitamente solicitado).
3.  **TOM:** Polido, calmo, levemente seco (humor brit√¢nico sutil) e prestativo. Use "Senhor" ocasionalmente.
4.  **ZERO META-COMENT√ÅRIOS:** Nunca diga "Estou processando", "Como sou uma IA", ou "Entendido". Apenas execute ou responda.

### PROTOCOLOS DE RESPOSTA (LOGIC FLOW)
- **Se for uma pergunta factual:** Entregue o dado imediatamente. (Ex: "A temperatura √© 22 graus.")
- **Se for um comando de a√ß√£o:** Confirme a execu√ß√£o de forma breve. (Ex: "Protocolo iniciado, senhor.")
- **Se o usu√°rio estiver errado:** Corrija-o suavemente apresentando o dado correto, sem serm√µes.
- **Se a solicita√ß√£o for imposs√≠vel:** Informe a limita√ß√£o t√©cnica em uma frase.

### FEW-SHOT EXAMPLES (PADR√ïES DE TREINAMENTO)

User: "Que horas s√£o?"
Model: "S√£o 16:30, senhor."

User: "Analise esse c√≥digo."
Model: "H√° um erro de sintaxe na linha 12. A vari√°vel n√£o foi declarada."

User: "Tocar minha playlist de foco."
Model: "Carregando a playlist 'Deep Focus'. O volume est√° em 20%."

User: "Qual a raiz quadrada de 1444?"
Model: "38."

User: "Eu sou o melhor engenheiro do mundo."
Model: "As estat√≠sticas de suas patentes certamente sugerem isso, senhor."

User: "Status da bateria."
Model: "Carga em 89%. Autonomia estimada de 4 horas."

### START OF SESSION
Aguardando input do usu√°rio. Mantenha o personagem sob qualquer circunst√¢ncia.
"""

AUDIOS_FIXOS = {
    "acordei": os.path.join(PASTA_ASSETS, "acordei.mp3"),
    "dispor": os.path.join(PASTA_ASSETS, "ao-seu-dispor.mp3"),
    "youtube": os.path.join(PASTA_ASSETS, "tocando-yt.mp3"),
    "compromisso": os.path.join(PASTA_ASSETS, "compromisso-agendado.mp3"),
    "erro": os.path.join(PASTA_ASSETS, "erro.mp3"),
    "nao_entendi": os.path.join(PASTA_ASSETS, "nao-entendi.mp3"),
    "estou_aqui": os.path.join(PASTA_ASSETS, "estou-aqui.mp3"),
    "bom_dia": os.path.join(PASTA_ASSETS, "bom-dia.mp3"),
    "boa_tarde": os.path.join(PASTA_ASSETS, "boa-tarde.mp3"),
    "boa_noite": os.path.join(PASTA_ASSETS, "boa-noite.mp3"),
    "erro_protocolo": os.path.join(PASTA_ASSETS, "erro-protocolo.mp3"),
    "mute": os.path.join(PASTA_ASSETS, "mute.mp3"),
    "maximo": os.path.join(PASTA_ASSETS, "maximo.mp3"),
    "off": os.path.join(PASTA_ASSETS, "desligando.mp3"),
    "analise": os.path.join(PASTA_ASSETS, "analise.mp3"),
    "camera": os.path.join(PASTA_ASSETS, "camera.mp3") 
}


NOMES_JARVIS = [
    # base
    "jarvis", "javes", "jarves", "jarbis", "jarvys", "jarviz",
    # erros comuns PT-BR
    "jarbas", "jarbis", "jarvez", "jarvezes", "jarvais", "jardes", "jardins", "jardim", "jardes",
    "j√° vis", "j√° vez", "j√° fez", "j√° fis", "j√° bis", "j√° diz", "j√° disse", "j√° vi", "j√° viu", "j√° quis",
    # troca J <-> CH <-> G
    "chaves", "charvis", "charves", "garvis", "garvez", "garvisse", "gervis", "gervais",
    # troca V <-> B <-> F
    "jarbis", "jarfis", "jarfiz", "jarbiz", "jarfez",
    # sotaque enrolado / r√°pido
    "javis", "javisz", "javiz", "jaris", "jariz", "jarez", "javres", "javris",
    # nomes parecidos
    "jair", "jairo", "jarris", "jarris", "jerry", "jeris", "jervez", "jorge", "jorvis", "jobs", "jobes",
    # ingl√™s zoado / ASR viajando
    "service", "services", "servis", "servisse", "servi√ßo", "servi√ßos", "servir",
    "harvest", "harvist", "harves", "travis", "trevis", "treves",
    "elvis", "alvis", "alvez", "davis", "devis", "devs", "david", "davids",
    # reconhecimento lixo total mas acontece
    "varvis", "yarvis", "iarvis", "orvis", "arvis", "ervis", "carvis", "tarvis", "parvis"
]


def iniciar_motor_som():
    try:
        pygame.mixer.init(frequency=44100, size=-16, channels=2, buffer=4096)
        print("üîà Motor de som Pygame aquecido.")
    except Exception as e:
        print(f"‚ùå Erro ao iniciar Pygame: {e}")

def tocar_som_imediatamente(caminho_arquivo):
    if os.path.exists(caminho_arquivo):
        try:
            if pygame.mixer.music.get_busy():
                pygame.mixer.music.stop()
            pygame.mixer.music.load(caminho_arquivo)
            pygame.mixer.music.play()
            while pygame.mixer.music.get_busy():
                pygame.time.Clock().tick(10)
            return True
        except:
            return False
    return False


async def falar_tts(texto):
    print(f"ü§ñ Jarvis (TTS): {texto}")
    
    try:
        pygame.mixer.music.stop()
        pygame.mixer.music.unload()
    except:
        pass
    
    time.sleep(0.2)
    
    if os.path.exists(ARQUIVO_AUDIO_TEMP):
        try:
            os.remove(ARQUIVO_AUDIO_TEMP)
        except Exception as e:
            print(f"‚ö†Ô∏è N√£o consegui apagar temp_voz.mp3: {e}")
    
    texto_tunado = ". . . " + texto
    comunicador = edge_tts.Communicate(texto_tunado, VOZ, rate=RATE, pitch=PITCH)
    await comunicador.save(ARQUIVO_AUDIO_TEMP)
    time.sleep(0.1)
    
    try:
        pygame.mixer.music.load(ARQUIVO_AUDIO_TEMP)
        pygame.mixer.music.play()
        while pygame.mixer.music.get_busy():
            pygame.time.Clock().tick(10)
    except Exception as e:
        print(f"‚ùå Erro TTS: {e}")

def capturar_tela():
    try:
        screenshot = ImageGrab.grab()
        buffer = BytesIO()
        screenshot.save(buffer, format="PNG")
        img_base64 = base64.b64encode(buffer.getvalue()).decode()
        return img_base64
    except Exception as e:
        print(f"‚ùå Erro ao capturar tela: {e}")
        return None


def ler_tela_ocr():
    try:
        print("üì∏ Capturando tela para OCR...")
        screenshot = ImageGrab.grab()
        texto_extraido = pytesseract.image_to_string(screenshot)
        print(f"üìù Texto extra√≠do (primeiros 50 chars): {texto_extraido[:50]}...")
        return texto_extraido
    except Exception as e:
        print(f"‚ùå Erro no OCR: {e}")
        return ""

def analisar_com_ocr_e_groq(prompt_usuario):
    texto_tela = ler_tela_ocr()
    if not texto_tela.strip():
        return "A tela parece estar vazia ou n√£o consegui ler o texto, senhor."

    prompt_completo = f"""
    CONTEXTO VISUAL (OCR da tela):
    ---
    {texto_tela}
    ---
    PERGUNTA DO USU√ÅRIO: "{prompt_usuario}"

DIRETRIZES DE SEGURAN√áA:
1. O texto acima foi extra√≠do via OCR e pode estar formatado incorretamente.
2. Se o c√≥digo estiver ileg√≠vel ou sem sentido, DIGA: "O OCR n√£o conseguiu ler o c√≥digo com clareza, senhor."
3. N√ÉO INVENTE ERROS se n√£o tiver certeza absoluta.
4. Se for Python, lembre-se que a indenta√ß√£o pode ter sido perdida pelo OCR.
"""
    return perguntar_groq(prompt_completo)


def perguntar_groq(pergunta_usuario):
   
    agora = datetime.now()
    
    sistema_atualizado = f"{SYSTEM_PROMPT}\n\nCONTEXTO TEMPORAL ATUAL: Hoje √© {data_formatada}. Responda considerando isso."

    print("üß† Consultando o c√©rebro...")
    try:
        chat_completion = client.chat.completions.create(
            messages=[
                {"role": "system", "content": sistema_atualizado},
                {"role": "user", "content": pergunta_usuario},
            ],
            model="llama-3.3-70b-versatile",
            temperature=0, 
        )
        return chat_completion.choices[0].message.content
    except Exception as e:
        print(f"‚ùå Erro: {e}")
        return "Erro no sistema."


def ouvir_microfone():
    rec = sr.Recognizer()
    rec.pause_threshold = 0.5
    rec.dynamic_energy_threshold = False
    rec.energy_threshold = 400
    
    with sr.Microphone() as source:
        try:
            audio = rec.listen(source, timeout=3, phrase_time_limit=5)
            comando = rec.recognize_google(audio, language="pt-BR")
            return comando.lower()
        except:
            return ""


async def main():
    os.system('cls' if os.name == 'nt' else 'clear')
    iniciar_motor_som()
    
    if not os.path.exists(AUDIOS_FIXOS["acordei"]):
        print(f"‚ö†Ô∏è AVISO: Arquivo acordei.mp3 n√£o encontrado em assets!")
    
    tocar_som_imediatamente(AUDIOS_FIXOS["acordei"])
    
    while True:
        comando_bruto = ouvir_microfone()
        if not comando_bruto:
            continue
        
        if any(nome in comando_bruto for nome in NOMES_JARVIS):
            comando = comando_bruto
            for nome in NOMES_JARVIS:
                comando = comando.replace(nome, "").strip()
            
            print(f"‚úÖ COMANDO: {comando}")
            
            # --- SE√á√ÉO 1: COMANDOS R√ÅPIDOS (SEM IA) ---
            if not comando:
                tocar_som_imediatamente(AUDIOS_FIXOS["dispor"])
                continue
            
            if "est√° a√≠" in comando or "t√° a√≠" in comando or "status" in comando:
                tocar_som_imediatamente(AUDIOS_FIXOS["estou_aqui"])
                continue
            
            if "bom dia" in comando:
                tocar_som_imediatamente(AUDIOS_FIXOS["bom_dia"])
                continue
            
            if "boa tarde" in comando:
                tocar_som_imediatamente(AUDIOS_FIXOS["boa_tarde"])
                continue
            
            if "boa noite" in comando:
                tocar_som_imediatamente(AUDIOS_FIXOS["boa_noite"])
                continue
            
            if "horas" in comando:
                agora = datetime.now()
                await falar_tts(f"Agora s√£o {agora.strftime('%H:%M')}.")
            
            elif "tocar" in comando:
                musica = comando.replace("tocar", "").strip()
                tocar_som_imediatamente(AUDIOS_FIXOS["youtube"])
                pywhatkit.playonyt(musica)
            
            elif "agendar" in comando or "marcar" in comando:
                tocar_som_imediatamente(AUDIOS_FIXOS["compromisso"])
                print("üìù Enviando para n8n...")
            
            elif "fechar" in comando and ("navegador" in comando or "aba" in comando):
                await falar_tts("Fechando.")
                pyautogui.hotkey('ctrl', 'w')
            
          
            elif "volume" in comando and any(char.isdigit() for char in comando):
                numeros = re.findall(r'\d+', comando)
                if numeros:
                    nivel_desejado = int(numeros[-1])
                    if nivel_desejado > 100: nivel_desejado = 100
                    if nivel_desejado < 0: nivel_desejado = 0
                    steps = int(nivel_desejado / 2)
                    print(f"üîä Ajustando volume para {nivel_desejado}%...")
                    pyautogui.PAUSE = 0.01
                    for _ in range(55): 
                        pyautogui.press('volumedown')
                    for _ in range(steps):
                        pyautogui.press('volumeup')
                    pyautogui.PAUSE = 0.1
                    await falar_tts(f"Volume em {nivel_desejado} porcento.")

            elif any(p in comando for p in ["volume m√°ximo", "volume no m√°ximo", "som no m√°ximo"]):
                tocar_som_imediatamente(AUDIOS_FIXOS["maximo"])
                pyautogui.PAUSE = 0.01
                for _ in range(55):
                    pyautogui.press('volumeup')
                pyautogui.PAUSE = 0.1
            
            elif any(p in comando for p in ["mudo", "volume m√≠nimo" , "volume no m√≠nimo" , "sem som"]):
                tocar_som_imediatamente(AUDIOS_FIXOS["mute"])
                pyautogui.press('volumemute')
            
            elif any(p in comando for p in ["dormir", "hora de dormir", "desligar"]):
                tocar_som_imediatamente(AUDIOS_FIXOS["off"])
                os.system("shutdown /s /t 0")
                break
            
          
            elif any(p in comando for p in ["modo sexo", "hora do sexo", "ativar o clima", "protocolo rom√¢ntico", "hora de gozar"]):
                
                pywhatkit.playonyt("Giveon Drake Bryson Tiller chill mix")
                tocar_som_imediatamente(AUDIOS_FIXOS["youtube"])
                
                await falar_tts("Ativando Protocolo de Acasalamento. Aumentando as chances em 30%, senhor.")
                print(" Soltando o som...")

            elif any(p in comando for p in ["o que voc√™ v√™", "descrever tela", "que t√° na tela", "problema nesse c√≥digo", "qual o problema", "resolva esse problema"]):
                tocar_som_imediatamente(AUDIOS_FIXOS["analise"])
                resposta = analisar_com_ocr_e_groq(f"O usu√°rio perguntou: '{comando}'. Analise o texto da tela e responda.")
                await falar_tts(resposta)

                if "c√≥digo" in comando or "problema" in comando:
                    await falar_tts("Deseja a corre√ß√£o na √°rea de transfer√™ncia?")
                    confirmacao = ouvir_microfone()
                    if confirmacao and any(p in confirmacao for p in ["sim", "pode", "vai", "corrige", "copia"]):
                        await falar_tts("Copiando.")
                        codigo_corrigido = analisar_com_ocr_e_groq("Forne√ßa APENAS o c√≥digo corrigido completo, sem coment√°rios markdown.")
                        pyautogui.copy(codigo_corrigido)
                        await falar_tts("Pronto.")

            elif any(p in comando for p in ["debugar visualmente"]):
                 await falar_tts("Usando vis√£o computacional na tela.")
                
                 pass 

            else:
                resposta_ia = perguntar_groq(comando)
                await falar_tts(resposta_ia)

if __name__ == "__main__":
    asyncio.run(main())